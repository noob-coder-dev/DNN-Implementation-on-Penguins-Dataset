{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc3538e9",
   "metadata": {},
   "source": [
    "## Explore the dataset\n",
    "\n",
    "Let's load the data we need from the Palmer Islands penguins dataset, which contains observations of three different species of penguin. \n",
    " \n",
    " **Citation**: The penguins dataset used in the this project is a subset of data collected and made available by [Dr.Â Kristen\n",
    "Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php)\n",
    "and the [Palmer Station, Antarctica LTER](https://pal.lternet.edu/), a\n",
    "member of the [Long Term Ecological Research\n",
    "Network](https://lternet.edu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fff8a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CulmenLength</th>\n",
       "      <th>CulmenDepth</th>\n",
       "      <th>FlipperLength</th>\n",
       "      <th>BodyMass</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>51.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>20.3</td>\n",
       "      <td>41.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>45.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>39.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>50.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>34.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>51.9</td>\n",
       "      <td>19.5</td>\n",
       "      <td>20.6</td>\n",
       "      <td>39.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>50.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.3</td>\n",
       "      <td>38.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>39.6</td>\n",
       "      <td>18.1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>44.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>55.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>56.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>49.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>22.1</td>\n",
       "      <td>63.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>45.4</td>\n",
       "      <td>18.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>35.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>51.3</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>37.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CulmenLength  CulmenDepth  FlipperLength  BodyMass  Species\n",
       "309          51.0         18.8           20.3     41.00        2\n",
       "281          45.2         17.8           19.8     39.50        2\n",
       "322          50.1         17.9           19.0     34.00        2\n",
       "336          51.9         19.5           20.6     39.50        2\n",
       "299          50.6         19.4           19.3     38.00        2\n",
       "93           39.6         18.1           18.6     44.50        0\n",
       "253          55.9         17.0           22.8     56.00        1\n",
       "169          49.2         15.2           22.1     63.00        1\n",
       "279          45.4         18.7           18.8     35.25        2\n",
       "285          51.3         19.9           19.8     37.00        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the training dataset (excluding rows with null values)\n",
    "penguins = pd.read_csv('penguins-Copy1.csv').dropna()\n",
    "\n",
    " to the bill measurements\n",
    "penguins['FlipperLength'] = penguins['FlipperLength']/10\n",
    "penguins['BodyMass'] = penguins['BodyMass']/100\n",
    "\n",
    "# The dataset is too small to be useful for deep learning\n",
    "# So I'll oversample it to increase its size\n",
    "for i in range(1,3):\n",
    "    penguins = penguins.append(penguins)\n",
    "\n",
    "# Display a random sample of 10 observations\n",
    "sample = penguins.sample(10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae11104",
   "metadata": {},
   "source": [
    "The **Species** column is the label our model will predict. Each label value represents a class of penguin species, encoded as 0, 1, or 2. The following code shows the actual species to which these class labels corrrespond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb7cd353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CulmenLength' 'CulmenDepth' 'FlipperLength' 'BodyMass' 'Species'] SpeciesName\n",
      "[ 49.3 15.7 21.7 58.5 1 ] Gentoo\n",
      "[ 40.1 18.9 18.8 43.0 0 ] Adelie\n",
      "[ 39.2 18.6 19.0 42.5 0 ] Adelie\n",
      "[ 55.8 19.8 20.7 40.0 2 ] Chinstrap\n",
      "[ 43.5 18.1 20.2 34.0 2 ] Chinstrap\n",
      "[ 44.9 13.3 21.3 51.0 1 ] Gentoo\n",
      "[ 52.7 19.8 19.7 37.25 2 ] Chinstrap\n",
      "[ 46.4 18.6 19.0 34.5 2 ] Chinstrap\n",
      "[ 37.3 17.8 19.1 33.5 0 ] Adelie\n",
      "[ 50.4 15.3 22.4 55.5 1 ] Gentoo\n"
     ]
    }
   ],
   "source": [
    "penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\n",
    "print(sample.columns[0:5].values, 'SpeciesName')\n",
    "for index, row in penguins.sample(10).iterrows():\n",
    "    print('[',row[0], row[1], row[2],row[3], int(row[4]), ']',penguin_classes[int(row[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d27ab0",
   "metadata": {},
   "source": [
    "As is common in a supervised learning problem, I'll split the dataset into a set of records with which to train the model, and a smaller set with which to validate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae778def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 957, Test Set: 411 \n",
      "\n",
      "Sample of features and labels:\n",
      "[51.1 16.5 22.5 52.5] 1 (Gentoo)\n",
      "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
      "[49.5 16.2 22.9 58. ] 1 (Gentoo)\n",
      "[39.3 20.6 19.  36.5] 0 (Adelie)\n",
      "[42.5 20.7 19.7 45. ] 0 (Adelie)\n",
      "[50.  15.3 22.  55.5] 1 (Gentoo)\n",
      "[50.2  18.7  19.8  37.75] 2 (Chinstrap)\n",
      "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
      "[49.1  14.5  21.2  46.25] 1 (Gentoo)\n",
      "[43.2 16.6 18.7 29. ] 2 (Chinstrap)\n",
      "[38.8  17.6  19.1  32.75] 0 (Adelie)\n",
      "[37.8 17.1 18.6 33. ] 0 (Adelie)\n",
      "[45.8 14.2 21.9 47. ] 1 (Gentoo)\n",
      "[43.8 13.9 20.8 43. ] 1 (Gentoo)\n",
      "[36.  17.1 18.7 37. ] 0 (Adelie)\n",
      "[43.3 13.4 20.9 44. ] 1 (Gentoo)\n",
      "[36.  18.5 18.6 31. ] 0 (Adelie)\n",
      "[41.1  19.   18.2  34.25] 0 (Adelie)\n",
      "[33.1 16.1 17.8 29. ] 0 (Adelie)\n",
      "[40.9 13.7 21.4 46.5] 1 (Gentoo)\n",
      "[45.2 17.8 19.8 39.5] 2 (Chinstrap)\n",
      "[48.4 14.6 21.3 58.5] 1 (Gentoo)\n",
      "[43.6 13.9 21.7 49. ] 1 (Gentoo)\n",
      "[38.5  17.9  19.   33.25] 0 (Adelie)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\n",
    "label = 'Species'\n",
    "   \n",
    "# Split data 70%-30% into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(penguins[features].values,\n",
    "                                                    penguins[label].values,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=0)\n",
    "\n",
    "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n",
    "print(\"Sample of features and labels:\")\n",
    "\n",
    "# Take a look at the first 25 training features and corresponding labels\n",
    "for n in range(0,24):\n",
    "    print(x_train[n], y_train[n], '(' + penguin_classes[y_train[n]] + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b5d09",
   "metadata": {},
   "source": [
    "The *features* are the measurements for each penguin observation, and the *label* is a numeric value that indicates the species of penguin that the observation represents (Adelie, Gentoo, or Chinstrap).\n",
    "\n",
    "## Install and import TensorFlow libraries\n",
    "\n",
    "Since I'm planning to use TensorFlow to create this penguin classifier, I'll need to run the following two cells to install and import the libraries I intend to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8faaefe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n",
      "Keras version: 2.4.0\n",
      "TensorFlow version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Set random seed for reproducability\n",
    "tensorflow.random.set_seed(0)\n",
    "\n",
    "print(\"Libraries imported.\")\n",
    "print('Keras version:',keras.__version__)\n",
    "print('TensorFlow version:',tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74705bf",
   "metadata": {},
   "source": [
    "## Prepare the data for TensorFlow\n",
    "\n",
    "I've already loaded our data and split it into training and validation datasets. However, I need to do some further data preparation so that this data will work correctly with TensorFlow. Specifically, I need to set the data type of the features to 32-bit floating point numbers, and specify that the labels represent categorical classes rather than numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94635922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready...\n"
     ]
    }
   ],
   "source": [
    "# Set data types for float features\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Set data types for categorical labels\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "print('Ready...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd6208d",
   "metadata": {},
   "source": [
    "## Define a neural network\n",
    "\n",
    "Now I'm ready to define our neural network. In this case, I'll create a network that consists of 3 fully-connected layers:\n",
    "* An input layer that receives an input value for each feature (in this case, the four penguin measurements) and applies a *ReLU* activation function.\n",
    "* A hidden layer that receives ten inputs and applies a *ReLU* activation function.\n",
    "* An output layer that uses a *SoftMax* activation function to generate an output for each penguin species (which represent the classification probabilities for each of the three possible penguin species). Softmax functions produce a vector with probability values that sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954fcfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a classifier network\n",
    "hl = 10 # Number of hidden layer nodes\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hl, input_dim=len(features), activation='relu'))\n",
    "model.add(Dense(hl, input_dim=hl, activation='relu'))\n",
    "model.add(Dense(len(penguin_classes), input_dim=hl, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6de385",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "To train the model, I need to repeatedly feed the training values forward through the network, use a loss function to calculate the loss, use an optimizer to backpropagate the weight and bias value adjustments, and validate the model using the test data we withheld.\n",
    "\n",
    "To do this, we'll apply an Adam optimizer to a categorical cross-entropy loss function iteratively over 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f58aeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 31.1438 - accuracy: 0.1969 - val_loss: 11.2900 - val_accuracy: 0.2165\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 7.8160 - accuracy: 0.2031 - val_loss: 1.5626 - val_accuracy: 0.1752\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3587 - accuracy: 0.1955 - val_loss: 1.1591 - val_accuracy: 0.3139\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1261 - accuracy: 0.3163 - val_loss: 1.0832 - val_accuracy: 0.4453\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0618 - accuracy: 0.4275 - val_loss: 1.0545 - val_accuracy: 0.4574\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0403 - accuracy: 0.4957 - val_loss: 1.0425 - val_accuracy: 0.4842\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0202 - accuracy: 0.5395 - val_loss: 1.0315 - val_accuracy: 0.5547\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0188 - accuracy: 0.6026 - val_loss: 1.0189 - val_accuracy: 0.6156\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9881 - accuracy: 0.6290 - val_loss: 1.0050 - val_accuracy: 0.6521\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9704 - accuracy: 0.6842 - val_loss: 0.9911 - val_accuracy: 0.6618\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9606 - accuracy: 0.7131 - val_loss: 0.9781 - val_accuracy: 0.6813\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.9432 - accuracy: 0.6961 - val_loss: 0.8758 - val_accuracy: 0.6350\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.8152 - accuracy: 0.7154 - val_loss: 0.7991 - val_accuracy: 0.7129\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.7371 - val_loss: 0.7380 - val_accuracy: 0.7202\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.7754 - val_loss: 0.6802 - val_accuracy: 0.7421\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6317 - accuracy: 0.7835 - val_loss: 0.6292 - val_accuracy: 0.7470\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.5733 - accuracy: 0.8021 - val_loss: 0.5871 - val_accuracy: 0.7567\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.8088 - val_loss: 0.5660 - val_accuracy: 0.7786\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8300 - val_loss: 0.5272 - val_accuracy: 0.7786\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8125 - val_loss: 0.4849 - val_accuracy: 0.7713\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8100 - val_loss: 0.4676 - val_accuracy: 0.7640\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8241 - val_loss: 0.4518 - val_accuracy: 0.7689\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.8290 - val_loss: 0.4383 - val_accuracy: 0.8054\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.8653 - val_loss: 0.3915 - val_accuracy: 0.8224\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8757 - val_loss: 0.3924 - val_accuracy: 0.8808\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8988 - val_loss: 0.3521 - val_accuracy: 0.8710\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.9232 - val_loss: 0.3362 - val_accuracy: 0.8759\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.9135 - val_loss: 0.3216 - val_accuracy: 0.9002\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.9255 - val_loss: 0.3074 - val_accuracy: 0.8929\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.9294 - val_loss: 0.2890 - val_accuracy: 0.9075\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2529 - accuracy: 0.9427 - val_loss: 0.2870 - val_accuracy: 0.8662\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.9327 - val_loss: 0.2752 - val_accuracy: 0.8832\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9393 - val_loss: 0.2491 - val_accuracy: 0.9148\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9539 - val_loss: 0.2343 - val_accuracy: 0.9367\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.9608 - val_loss: 0.2233 - val_accuracy: 0.9489\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1979 - accuracy: 0.9606 - val_loss: 0.2061 - val_accuracy: 0.9635\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9592 - val_loss: 0.2004 - val_accuracy: 0.9562\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9649 - val_loss: 0.1851 - val_accuracy: 0.9732\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9670 - val_loss: 0.1749 - val_accuracy: 0.9757\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9637 - val_loss: 0.1627 - val_accuracy: 0.9684\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9782 - val_loss: 0.1555 - val_accuracy: 0.9708\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9680 - val_loss: 0.1717 - val_accuracy: 0.9465\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9764 - val_loss: 0.1403 - val_accuracy: 0.9805\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9787 - val_loss: 0.1313 - val_accuracy: 0.9781\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9741 - val_loss: 0.1223 - val_accuracy: 0.9805\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9804 - val_loss: 0.1165 - val_accuracy: 0.9830\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.9794 - val_loss: 0.1173 - val_accuracy: 0.9732\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0921 - accuracy: 0.9819 - val_loss: 0.1118 - val_accuracy: 0.9805\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9839 - val_loss: 0.1018 - val_accuracy: 0.9830\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9854 - val_loss: 0.1046 - val_accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "#hyper-parameters for optimizer\n",
    "learning_rate = 0.001\n",
    "opt = optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model over 50 epochs using 10-observation batches and using the test holdout dataset for validation\n",
    "num_epochs = 50\n",
    "history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063b09d0",
   "metadata": {},
   "source": [
    "## Review training and validation loss\n",
    "\n",
    "After training is complete, I can examine the loss metrics I've recorded while training and validating the model. I'm looking for two things:\n",
    "* The loss should reduce with each epoch, showing that the model is learning the right weights and biases to predict the correct labels.\n",
    "* The training loss and validation loss should follow a similar trend, showing that the model is not overfitting to the training data.\n",
    "\n",
    "Let's plot the loss metrics and see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e0b47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "epoch_nums = range(1,num_epochs+1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22475af5",
   "metadata": {},
   "source": [
    "## View the learned weights and biases\n",
    "\n",
    "The trained model consists of the final weights and biases that were determined by the optimizer during training. Based on this network model I should expect the following values for each layer:\n",
    "* Layer 1: There are four input values going to ten output nodes, so there should be 4 x 10 weights and 10 bias values.\n",
    "* Layer 2: There are ten input values going to ten output nodes, so there should be 10 x 10 weights and 10 bias values.\n",
    "* Layer 3: There are ten input values going to three output nodes, so there should be 10 x 3 weights and 3 bias values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "489d9938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Weights:\n",
      " [[-0.27236846 -0.3841947   0.03324002  0.08020484 -0.10909867  0.05677444\n",
      "  -0.19284697  0.8463786   0.35794353 -0.4905011 ]\n",
      " [ 0.27471453  0.21265197  0.08151422 -0.17707926 -0.10406601  0.80808705\n",
      "   0.34789595 -0.05428036 -0.6077915  -0.5447268 ]\n",
      " [-0.28836262 -0.634329    0.2833845   0.34767175  0.23550075 -0.01212112\n",
      "   0.14559276 -0.7978691  -0.5164287   0.3296095 ]\n",
      " [-0.42851955 -0.24623463 -0.28597653 -0.5230521  -0.43773973  0.36985767\n",
      "  -0.0764817   0.23638226  0.7525387  -0.4691702 ]] \n",
      "Biases:\n",
      " [ 0.          0.         -0.01292539  0.          0.          0.20184611\n",
      " -0.19173318 -0.2613485  -0.31521487  0.        ]\n",
      "------------\n",
      "Weights:\n",
      " [[ 0.0607031  -0.30530828  0.39975524  0.3037489   0.15896738  0.03326017\n",
      "  -0.53190327  0.40915883 -0.03316814 -0.1240823 ]\n",
      " [ 0.42301047  0.14984506 -0.54566675  0.3919103  -0.4295466   0.50397205\n",
      "  -0.31616646  0.17803025 -0.41518384 -0.38429344]\n",
      " [ 0.5336163   0.37752342 -0.4694244   0.17206895 -0.04215616  0.5297911\n",
      "   0.4356906   0.28243893  0.26588047 -0.2233491 ]\n",
      " [-0.04491103  0.19579428 -0.26655364  0.17358297  0.3112036   0.53520477\n",
      "  -0.3109483  -0.5284722  -0.00098199 -0.44063687]\n",
      " [ 0.5135      0.39074183  0.39206952 -0.03048635  0.02663547  0.20555359\n",
      "   0.09307003  0.24590033 -0.49007446 -0.2917699 ]\n",
      " [ 0.5036509  -0.3901862   0.6040683   0.29417115 -0.26569188 -0.5313456\n",
      "   0.41427454 -0.15646034  0.00371227 -0.04586926]\n",
      " [ 0.26545775 -0.19090915  0.06543597 -0.30627972  0.12806404 -0.38203925\n",
      "  -0.21518531  0.41642922  0.2622466  -0.49726105]\n",
      " [-0.43842497 -0.21495155 -0.14270845 -0.46094683 -0.20800981  0.3025053\n",
      "  -0.01376527  0.4088537   0.27342096 -0.25861204]\n",
      " [-0.5077288  -0.4176368  -0.24631909 -0.49696004 -0.27225545 -0.38996994\n",
      "  -0.40839186  0.16560256 -0.26306108  0.2282074 ]\n",
      " [ 0.32320213 -0.30822456 -0.37115166  0.45703936 -0.35191107  0.24120325\n",
      "  -0.2000556   0.23292273 -0.33508268 -0.51532805]] \n",
      "Biases:\n",
      " [-0.03101528  0.          0.4381842   0.          0.          0.\n",
      "  0.1223659  -0.2920466  -0.30325168 -0.0152769 ]\n",
      "------------\n",
      "Weights:\n",
      " [[-0.3835068   0.32607827 -0.04719009]\n",
      " [ 0.50995994 -0.12620813 -0.6595991 ]\n",
      " [ 0.5340331   0.02766317 -0.21622917]\n",
      " [ 0.54463303 -0.50025463  0.06109887]\n",
      " [ 0.26757038 -0.67376095 -0.18467396]\n",
      " [ 0.08888024 -0.2536324   0.20257705]\n",
      " [ 1.1713442  -1.5687052   0.6411084 ]\n",
      " [-0.49163952  0.38573593  0.1955237 ]\n",
      " [-0.5256168  -0.34712172  0.6831371 ]\n",
      " [ 0.6409571  -0.6129823  -0.03113725]] \n",
      "Biases:\n",
      " [ 0.32175827  0.46051517 -0.4932575 ]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()[0]\n",
    "    biases = layer.get_weights()[1]\n",
    "    print('------------\\nWeights:\\n',weights,'\\nBiases:\\n', biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33136ec",
   "metadata": {},
   "source": [
    "## Evaluate model performance\n",
    "\n",
    "So, is the model any good? The raw accuracy reported from the validation data would seem to indicate that it predicts pretty well; but it's typically useful to dig a little deeper and compare the predictions for each possible class. A common way to visualize the performace of a classification model is to create a *confusion matrix* that shows a crosstab of correct and incorrect predictions for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0bc9a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class_probabilities = model.predict(x_test)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(penguin_classes))\n",
    "plt.xticks(tick_marks, penguin_classes, rotation=85)\n",
    "plt.yticks(tick_marks, penguin_classes)\n",
    "plt.xlabel(\"Actual Class\")\n",
    "plt.ylabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df48019d",
   "metadata": {},
   "source": [
    "The confusion matrix should show a strong diagonal line indicating that there are more correct than incorrect predictions for each class.\n",
    "\n",
    "## Save the trained model\n",
    "Now that we have a model we believe is reasonably accurate, we can save its trained weights for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb64c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
